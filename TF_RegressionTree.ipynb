{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "from six.moves import urllib\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Dataset\n",
    "\n",
    "path = \"/home/petra/tfx/data/wine-quality.csv\"\n",
    "\n",
    "dataset = pd.read_csv(path)\n",
    "\n",
    "#labels = dataset['quality']\n",
    "\n",
    "x_train, x_test = train_test_split(dataset, train_size=0.7)\n",
    "y_train = x_train.pop('quality')\n",
    "y_test = x_test.pop('quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "589     6\n",
       "1591    6\n",
       "16      6\n",
       "2973    6\n",
       "3799    5\n",
       "       ..\n",
       "4688    6\n",
       "4809    6\n",
       "3354    7\n",
       "13      7\n",
       "3143    5\n",
       "Name: quality, Length: 3428, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERIC_COLUMNS = ['alcohol', 'chlorides', 'citric_acid', 'density', 'fixed_acidity',\n",
    "                   'free_sulfur_dioxide', 'pH', 'residual_sugar', 'sulphates',\n",
    "                   'total_sulfur_dioxide', 'volatile_acidity']\n",
    "\n",
    "LABEL = 'quality'\n",
    "\n",
    "feature_columns = []\n",
    "for feature_name in NUMERIC_COLUMNS:\n",
    "    feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumericColumn(key='alcohol', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='chlorides', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='citric_acid', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='density', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='fixed_acidity', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='free_sulfur_dioxide', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='pH', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='residual_sugar', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='sulphates', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='total_sulfur_dioxide', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "NumericColumn(key='volatile_acidity', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n"
     ]
    }
   ],
   "source": [
    "for _ in feature_columns:\n",
    "    print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_fn(data_df, label_df, num_epochs=None, shuffle=True, batch_size=1000):\n",
    "  def input_function():\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\n",
    "    if shuffle:\n",
    "      ds = ds.shuffle(batch_size)\n",
    "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "    return ds\n",
    "  return input_function\n",
    "\n",
    "train_input_fn = make_input_fn(x_train, y_train, batch_size=len(x_train))\n",
    "eval_input_fn = make_input_fn(x_test, y_test, num_epochs=1, shuffle=False, batch_size=len(x_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpbsw_mcyi\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpbsw_mcyi', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpbsw_mcyi/model.ckpt.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 35.362892, step = 0\n",
      "INFO:tensorflow:global_step/sec: 32.8747\n",
      "INFO:tensorflow:loss = 1.0549853, step = 99 (3.043 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.388\n",
      "INFO:tensorflow:loss = 0.3490648, step = 199 (4.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.7302\n",
      "INFO:tensorflow:loss = 0.30261737, step = 299 (5.339 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 350...\n",
      "INFO:tensorflow:Saving checkpoints for 350 into /tmp/tmpbsw_mcyi/model.ckpt.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 350...\n",
      "INFO:tensorflow:Loss for final step: 0.28966355.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.boosted_trees.BoostedTreesRegressor at 0x7f76c44120d0>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since data fits into memory, use entire dataset per layer. It will be faster.\n",
    "# Above one batch is defined as the entire dataset.\n",
    "n_batches = 1\n",
    "est = tf.estimator.BoostedTreesRegressor(feature_columns,\n",
    "                                          n_batches_per_layer=n_batches,\n",
    "                                          n_trees=50, \n",
    "                                          max_depth=7,\n",
    "                                          learning_rate=0.02\n",
    "                                         )\n",
    "\n",
    "est.train(train_input_fn, max_steps=500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-01-07T23:34:05Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpbhzs76_q/model.ckpt-350\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.16481s\n",
      "INFO:tensorflow:Finished evaluation at 2021-01-07-23:34:05\n",
      "INFO:tensorflow:Saving dict for global step 350: average_loss = 0.43126994, global_step = 350, label/mean = 5.869748, loss = 0.43126994, prediction/mean = 5.884742\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 350: /tmp/tmpbhzs76_q/model.ckpt-350\n",
      "                          0\n",
      "average_loss       0.431270\n",
      "label/mean         5.869748\n",
      "loss               0.431270\n",
      "prediction/mean    5.884742\n",
      "global_step      350.000000\n"
     ]
    }
   ],
   "source": [
    "# Eval.\n",
    "result = est.evaluate(eval_input_fn)\n",
    "#clear_output()\n",
    "print(pd.Series(result).to_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> serving_input_receiver_fn = <function serving_input_receiver_fn at 0x7f76c4414290>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'placeholder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-15a614451e9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--> serving_input_receiver_fn = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserving_input_receiver_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir_base\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/home/petra/tfx/data/model\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserving_input_receiver_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserving_input_receiver_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/env_tfx/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mexport_saved_model\u001b[0;34m(self, export_dir_base, serving_input_receiver_fn, assets_extra, as_text, checkpoint_path, experimental_mode)\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[0mas_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m         strip_default_attrs=True)\n\u001b[0m\u001b[1;32m    726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m   def experimental_export_all_saved_models(self,\n",
      "\u001b[0;32m~/miniconda3/envs/env_tfx/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_export_all_saved_models\u001b[0;34m(self, export_dir_base, input_receiver_fn_map, assets_extra, as_text, checkpoint_path, strip_default_attrs)\u001b[0m\n\u001b[1;32m    857\u001b[0m             \u001b[0msave_variables\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             strip_default_attrs=strip_default_attrs)\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0msave_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/env_tfx/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_add_meta_graph_for_mode\u001b[0;34m(self, builder, input_receiver_fn_map, checkpoint_path, save_variables, mode, export_tags, check_variables, strip_default_attrs)\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_random_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_random_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m       \u001b[0minput_receiver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_receiver_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m       \u001b[0;31m# Call the model_fn and collect the export_outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-87-15a614451e9c>\u001b[0m in \u001b[0;36mserving_input_receiver_fn\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mserving_input_receiver_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mServingInputReceiver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
     ]
    }
   ],
   "source": [
    "#feature_columns.pop(\"VocabularyListCategoricalColumn\")\n",
    "#print(\"--> FEATURE_COLUMNS = \" + str(feature_columns))\n",
    "\n",
    "def serving_input_receiver_fn():\n",
    "    inputs = {\"x\": tf.placeholder(shape=[None, 11], dtype=tf.float32)}\n",
    "    return tf.estimator.export.ServingInputReceiver(inputs, inputs)\n",
    "\n",
    "print(\"--> serving_input_receiver_fn = \" + str(serving_input_receiver_fn))\n",
    "\n",
    "est.export_saved_model(export_dir_base=\"/home/petra/tfx/data/model\", serving_input_receiver_fn=serving_input_receiver_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _example_serving_receiver_fn(tf_transform_graph, schema):\n",
    "  \"\"\"Build the serving in inputs.\n",
    "  \n",
    "  Args:\n",
    "    tf_transform_graph: A TFTransformOutput.\n",
    "    schema: the schema of the input data.\n",
    "    \n",
    "  Returns:\n",
    "    Tensorflow graph which parses examples, applying tf-transform to them.\n",
    "  \"\"\"\n",
    "\n",
    "  # Get feature specifications and remove label\n",
    "  raw_feature_spec = _get_raw_feature_spec(schema)\n",
    "  raw_feature_spec.pop(LABEL_KEY)\n",
    "  \n",
    "  # Creates a serving_input_receiver_fn that expects a serialized tf.Example\n",
    "  # fed into a string placeholder. The function parses the tf.Example according\n",
    "  # to the provided feature_spec, and returns all parsed Tensors as features.\n",
    "  raw_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(\n",
    "      raw_feature_spec, default_batch_size=None)\n",
    "  serving_input_receiver = raw_input_fn()\n",
    "    \n",
    "      \n",
    "  # Transform the features according to the transform_graph\n",
    "  transformed_features = tf_transform_graph.transform_raw_features(\n",
    "      serving_input_receiver.features)\n",
    "\n",
    "  return tf.estimator.export.ServingInputReceiver(\n",
    "      transformed_features, serving_input_receiver.receiver_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_serving_input_fn(tf_transform_output):\n",
    "  \"\"\"Creates an input function reading from raw data.\n",
    "\n",
    "  Args:\n",
    "    tf_transform_output: Wrapper around output of tf.Transform.\n",
    "\n",
    "  Returns:\n",
    "    The serving input function.\n",
    "  \"\"\"\n",
    "  raw_feature_spec = RAW_DATA_FEATURE_SPEC.copy()\n",
    "  # Remove label since it is not available during serving.\n",
    "  raw_feature_spec.pop(LABEL_KEY)\n",
    "\n",
    "  def serving_input_fn():\n",
    "    \"\"\"Input function for serving.\"\"\"\n",
    "    # Get raw features by generating the basic serving input_fn and calling it.\n",
    "    # Here we generate an input_fn that expects a parsed Example proto to be fed\n",
    "    # to the model at serving time.  See also\n",
    "    # tf.estimator.export.build_raw_serving_input_receiver_fn.\n",
    "    raw_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(\n",
    "        raw_feature_spec, default_batch_size=None)\n",
    "    serving_input_receiver = raw_input_fn()\n",
    "\n",
    "    # Apply the transform function that was used to generate the materialized\n",
    "    # data.\n",
    "    raw_features = serving_input_receiver.features\n",
    "    transformed_features = tf_transform_output.transform_raw_features(\n",
    "        raw_features)\n",
    "\n",
    "    return tf.estimator.export.ServingInputReceiver(\n",
    "        transformed_features, serving_input_receiver.receiver_tensors)\n",
    "\n",
    "  return serving_input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf_transform_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-08d87551a9c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Export the model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mserving_input_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_serving_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_transform_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mexported_model_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworking_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEXPORTED_MODEL_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexported_model_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserving_input_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf_transform_output' is not defined"
     ]
    }
   ],
   "source": [
    "# Export the model.\n",
    "serving_input_fn = _make_serving_input_fn(tf_transform_output)\n",
    "exported_model_dir = os.path.join(working_dir, EXPORTED_MODEL_DIR)\n",
    "estimator.export_saved_model(exported_model_dir, serving_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
